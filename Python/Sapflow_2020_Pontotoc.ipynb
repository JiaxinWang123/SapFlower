{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "13RXOoF15ivCxytGp2ATun-J7LvfE-TdW",
      "authorship_tag": "ABX9TyP73ZjdUZwTCMOoh9w//W4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiaxinWang123/SapFlower/blob/main/Sapflow_2020_Pontotoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PirMKZ8SH32V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkD0IxN1Gee9"
      },
      "outputs": [],
      "source": [
        "#### Training BiLSTM model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the file path for saving the CSV\n",
        "csv_file_path = \"/content/drive/MyDrive/Sapflow_epoch50/best_rmse_per_clone.csv\"\n",
        "\n",
        "# Define the Bi-LSTM model\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size=8, hidden_layer_size=80, output_size=1):  # Change input size to 8\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size, bidirectional=True)  # Bi-directional LSTM\n",
        "\n",
        "        self.linear = nn.Linear(hidden_layer_size * 2, output_size)  # Double the hidden size for bidirectional LSTM\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1))\n",
        "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# Load the data\n",
        "data_origin = pd.read_csv(\"/content/Pontotoc_2020_Sapflow_Cleaned_day153_280_removed_outliners.csv\")\n",
        "\n",
        "# Drop NaN values and select relevant columns\n",
        "selected_columns = ['Date', 'VPD', 'PAR_Den_Avg']  # Remove the clone column from selected columns\n",
        "subset_data = data_origin[selected_columns].copy()  # Make a copy of the DataFrame\n",
        "\n",
        "# Define a dictionary to store the best RMSE for each clone\n",
        "best_rmse_dict = {}\n",
        "\n",
        "# Iterate over all clones from column index 5 to the end of the dataset\n",
        "for clone_index in range(5, len(data_origin.columns)):\n",
        "    clone = data_origin.columns[clone_index]  # Get the clone name from column index\n",
        "    clone_data = data_origin[['Date', 'VPD', 'PAR_Den_Avg', clone]].copy()  # Make a copy of the DataFrame\n",
        "\n",
        "    # Drop NaN values for the current clone\n",
        "    clone_data.dropna(inplace=True)\n",
        "    clone_data = clone_data[clone_data[clone].values > 0.005]\n",
        "\n",
        "    # Rename the columns for clarity\n",
        "    clone_data.columns = ['Date', 'VPD', 'PAR_Den_Avg', clone]\n",
        "\n",
        "    # Prepare data for training\n",
        "    data = clone_data\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "    # Extract hour from the date\n",
        "    data['Hour'] = data['Date'].dt.hour\n",
        "    data['Date'] = data['Date'].dt.date\n",
        "\n",
        "    # Convert date to ordinal\n",
        "    data['Date'] = data['Date'].apply(lambda x: x.toordinal())\n",
        "\n",
        "    # Convert hour to one-hot encoding\n",
        "    data = pd.get_dummies(data, columns=['Hour'], prefix='Hour')\n",
        "\n",
        "    # Normalize the other columns\n",
        "    scaler = StandardScaler()\n",
        "    data['Date'] = scaler.fit_transform(data['Date'].values.reshape(-1,1))\n",
        "    data['PAR_Den_Avg'] = scaler.fit_transform(data['PAR_Den_Avg'].values.reshape(-1,1))\n",
        "    data['VPD'] = scaler.fit_transform(data['VPD'].values.reshape(-1,1))\n",
        "\n",
        "    # Define the input and target variables\n",
        "    X = data[['Date', 'VPD', 'PAR_Den_Avg'] + [col for col in data.columns if col.startswith('Hour_')]].values\n",
        "    y = data[clone].values\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
        "\n",
        "    # Convert the data into PyTorch tensors and move them to GPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    X_train_tensor = torch.tensor(X_train).float().to(device)\n",
        "    y_train_tensor = torch.tensor(y_train).float().to(device)\n",
        "\n",
        "    X_test_tensor = torch.tensor(X_test).float().to(device)\n",
        "    y_test_tensor = torch.tensor(y_test).float().to(device)\n",
        "\n",
        "    # Define the model, loss function, and optimizer and move the model to GPU\n",
        "    model = BiLSTM(input_size=X.shape[1], hidden_layer_size=80, output_size=1).to(device)\n",
        "    loss_function = nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model multiple times and select the best fit model based on RMSE\n",
        "    best_rmse = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    num_trainings = 5  # Number of times to train the model\n",
        "    for _ in range(num_trainings):\n",
        "\n",
        "        # Train the model\n",
        "        epochs = 50\n",
        "        for i in range(epochs):\n",
        "            optimizer.zero_grad()\n",
        "            model.hidden = (torch.zeros(2, 1, model.hidden_layer_size).to(device),  # Bidirectional LSTM has 2 layers\n",
        "                            torch.zeros(2, 1, model.hidden_layer_size).to(device))\n",
        "\n",
        "            y_pred = model(X_train_tensor)\n",
        "\n",
        "            loss = loss_function(y_pred, y_train_tensor.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 5 == 1:\n",
        "                print(f'epoch: {i:3} loss: {loss.item():10.8f}')\n",
        "\n",
        "        # Evaluate the model\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_test_tensor)\n",
        "            loss = loss_function(preds, y_test_tensor.unsqueeze(1))\n",
        "            print(f'Test loss: {loss.item()}')\n",
        "\n",
        "        # Calculate RMSE\n",
        "        rmse = mean_squared_error(y_test, preds.cpu().numpy(), squared=False)\n",
        "        print(f'RMSE: {rmse}')\n",
        "\n",
        "        # Check if current model is the best fit\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_model = model\n",
        "\n",
        "    # Store the best RMSE for this clone in the dictionary\n",
        "    best_rmse_dict[clone] = best_rmse\n",
        "\n",
        "    # Use the best model for predictions\n",
        "    with torch.no_grad():\n",
        "        preds = best_model(X_test_tensor)\n",
        "        loss = loss_function(preds, y_test_tensor.unsqueeze(1))\n",
        "        print(f'Best model test loss: {loss.item()}')\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(preds.cpu().numpy(), label='Predicted')\n",
        "    plt.plot(y_test, label='True')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate RMSE using the best model\n",
        "    rmse = mean_squared_error(y_test, preds.cpu().numpy(), squared=False)\n",
        "    print(f'Best model RMSE: {rmse}')\n",
        "\n",
        "    # Save the best model state\n",
        "    torch.save(best_model.state_dict(), f'/content/drive/MyDrive/Sapflow_epoch50/model_{clone}_model_state_dict.pt')\n",
        "\n",
        "    # Write clone and best RMSE to the CSV file\n",
        "    with open(csv_file_path, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Clone', 'Best_RMSE'])  # Write header\n",
        "        for clone, rmse in best_rmse_dict.items():\n",
        "            writer.writerow([clone, rmse])\n"
      ]
    }
  ]
}